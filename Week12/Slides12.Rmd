---
title: "Models with Ordinal Variables Using the brms R Package"
author: "Ben Goodrich"
date: "`r format(Sys.time(), '%B %d, %Y')`"
autosize: true
header-includes:
   - \usepackage{amsmath}
   - \usepackage{amssymb}
   - \usepackage{color}
output:
  ioslides_presentation:
    widescreen: yes
editor_options: 
  chunk_output_type: console
---
<style type="text/css">
slides > slide:not(.nobackground):after {
  content: '';
}
</style>

```{r setup, include=FALSE}
options(width = 90)
options(mc.cores = parallel::detectCores())
library(knitr)
library(knitr)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines)==1) {        # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(4, 4, .1, .1), las = 1)  # smaller margin on top and right
})
library(brms)
```

## Structured Nonlinear Model

* The `stan_gamm4` package in **rstanarm** can estimate effects that are arbitrary smooth functions of
  predictors, as can `brm`
* `brm` can do that and estimate many more models with particular non-linear forms (that are just pasted into
  a Stan program)
* Examples from a brms [vignette](https://cran.r-project.org/web/packages/brms/vignettes/brms_nonlinear.html)
* It is a good idea to put the outcome variable in reasonable units

```{r, insurance, cache = TRUE, results = "hide", message = FALSE}
url <- "https://raw.githubusercontent.com/mages/diesunddas/master/Data/ClarkTriangle.csv"
loss <- readr::read_csv(url)
loss$cum <- loss$cum / 1000
fit_loss <- brm(brms::bf(cum ~ ult * (1 - exp(-(dev / theta) ^ omega)),
                         ult ~ 1, omega ~ 1, theta ~ 1, nl = TRUE),
                data = loss, family = gaussian(),
                prior = c(prior(normal(5, 1), nlpar = "ult"),
                          prior(normal(1, 2), nlpar = "omega"),
                          prior(normal(45, 10), nlpar = "theta")),
                control = list(adapt_delta = 0.9))
```

## Resulting Nonlinear Plot

```{r}
plot(conditional_effects(fit_loss), points = TRUE)
```

## Data-Generating Process for Interval Outcomes

$$\alpha \thicksim ??? \\
  \forall k: \beta_k \thicksim ??? \\
  \forall n: \mu_n \equiv \alpha + \sum_{k = 1}^K \beta_k x_{nk} \\
  \sigma \thicksim ??? \\
  \forall n: \epsilon_n \thicksim \mathcal{N}\left(0,\sigma\right) \\
  \forall n: y_n^\ast \equiv \mu_n + \epsilon_n \\
  y_n \equiv \sum_{j = 1}^{J - 1} \mathbb{I}\{y_n^\ast > z_j\}$$

Each $z_j$ is a KNOWN cutpoint, such as in "Is your family income between \$0 and \$20,000, 
\$20,000 and \$50,000, \$50,000 and \$100,000, \$100,000 and \$200,000, or more than \$200,000?"

## Log-Likelihood for Interval Outcomes

$$\ell\left(\alpha, \beta_1, \dots, \beta_K, \sigma\right) = 
\sum_{n = 1}^N \ln \Pr\left(y_n \mid \alpha, \beta_1, \dots, \beta_K, \sigma\right) = \\
\sum_{n = 1}^N \ln \left(F\left(z_{y_n} \mid \mu_n, \sigma\right) - 
F\left(z_{y_n - 1} \mid \mu_n, \sigma\right)\right)$$

where $F$ is the normal CDF (but could easily be another CDF).

```{r, eval = FALSE}
brm(z[y - 1]  | cens("interval", z[y]) ~ x1 + ... xk, 
    data = dataset, family = gaussian, prior = ???)
```

## Data-Generating Process for Ordinal Outcomes

<div class="columns-2">
$$\forall k: \beta_k \thicksim ??? \\
  \forall n: \eta_n \equiv \sum_{k = 1}^K \beta_k x_{nk} \\
  \forall n: \epsilon_n \thicksim \mathcal{N}\left(0,1\right) \\
  \forall n: y_n^\ast \equiv \eta_n + \epsilon_n \\
  \zeta_1 \equiv -\infty \\
  \forall j > 1: \zeta_j \thicksim ??? \\
  y_n \equiv \sum_{j = 1}^{J - 1} \mathbb{I}\{y_n^\ast > \zeta_j\}$$

* Each $\zeta_j$ is a UNKNOWN cutpoint (if $j > 1$), such as in "Do you approve, neither approve nor disapprove, 
or disapprove of the job Joe Biden is doing as President?" to estimate
* $\alpha \equiv 0$ because you could shift $\alpha$ by any constant & shift each $\zeta_j$ by
  the same constant without affecting $y_n$
* $\sigma \equiv 1$ because you could scale each $y_n^\ast$ by any positive constant & scale each 
  $\zeta_j$ by the same constant without affecting $y_n$, i.e. only RELATIVE values of $y_n^\ast$ 
  matter
</div>

## Likelihood for an Ordered Observation

* Likelihood for an observation is just categorical: $\mathcal{L}\left(\beta, \boldsymbol{\zeta};y\right) \propto\prod_{j=1}^{J}\Pr\left(\left.y=j\right|\beta, \boldsymbol{\zeta}\right)$
* If $F\left(\right)$ is in the location-scale family (normal, logistic,
etc.), then $F\left(\beta x +\epsilon\leq\zeta_{j}\right)=F_{0,1}\left(\zeta_{j}-\beta x\right)$,
where $F_{0,1}\left(\right)$ is the "standard" version of the CDF
* $\Pr\left(\left.y=j\right|\beta, \boldsymbol{\zeta}\right) = 
   F\left(\beta x +\epsilon\leq\zeta_{j}\right) -
   F\left(\beta x +\epsilon\leq\zeta_{j - 1}\right)$


## Graphs of Standard Normal Utility with Cutpoints

```{r, echo = FALSE, small.mar = TRUE}
p <- ppoints(1000)
x <- qnorm(p)
par(mar = c(4, 4, .1, .1), las = 1, mfcol = 1:2)
plot(x, dnorm(x), type = "l", xlab = "Utility", ylab = "Density")
cutpoints <- x[c(100, 200, 400, 700)]
segments(x0 = cutpoints, y0 = 0, y1 = dnorm(cutpoints), 
         col = "red", lty = "dashed")
plot(x, pnorm(x), type = "l", xlab = "Utility", ylab = "Cumulative Density")
segments(x0 = cutpoints, y0 = 0, y1 = pnorm(cutpoints),
         col = "red", lty = "dashed")
segments(x0 = -10, y0 = pnorm(cutpoints), x1 = cutpoints,
         col = "red", lty = "dashed")

```

## Estimating an Ordinal Model with `stan_polr`

```{r, polr, cache = TRUE, results = "hide", message = FALSE, warning = FALSE}
library(rstanarm); options(mc.cores = parallel::detectCores())
data("inhaler", package = "brms")
inhaler$rating <- as.ordered(inhaler$rating)
post <- stan_polr(rating ~ treat + period + carry, data = inhaler, 
                  method = "probit", prior = R2(0.25), seed = 12345)
```
* Now we can estimate the causal effect of `treat` on utility for `rating`:
```{r}
nd <- inhaler; nd$treat <- 1
y1_star <- posterior_linpred(post, newdata = nd)
nd$treat <- 0
y0_star <- posterior_linpred(post, newdata = nd)
summary(c(y1_star - y0_star))
```

## Results of `rstanarm::stan_polr`

```{r, output.lines = c(5:16)}
print(post, digits = 2)
```

## Similar Model with `brms::brm`

* `brm` can estimate similar models, but with priors on the coefficients
```{r, brm1, cache = TRUE, results = "hide", message = FALSE, warning = FALSE}
post <- brm(rating ~ treat + period + carry, data = inhaler, 
            family = cumulative(link = "probit"),
            prior = prior("logistic(0, 1)", class = "b"))
```
```{r, output.lines = -c(1:6)}
post # Intercept[j] corresponds to cutpoint[j] from stan_polr
```

## Can use `loo` (if you had multiple models)

```{r}
loo(post)
```

## Dirichlet Distribution

- Dirichlet distribution is a PDF over PMFs that has the following form
$$\begin{eqnarray*}
f\left(\left.\boldsymbol{\theta}\right|\boldsymbol{a}\right) & = & \frac{1}{B\left(\boldsymbol{a}\right)}\prod_{j=1}^{J}\theta_{j}^{a_{j}-1}
\end{eqnarray*}$$
where $a_{j}\geq 0\,\forall j$ and the multivariate Beta
function is $B\left(\boldsymbol{a}\right)=\frac{\prod_{j=1}^{J}\Gamma\left(a_{j}\right)}{\Gamma\left(\prod_{k=1}^{K}a_{j}\right)}$
where $\Gamma\left(z\right)=\int_{0}^{\infty}u^{z-1}e^{-u}du$ is
the Gamma function, which is implemented in R as `gamma`
- $\mathbb{E}\theta_{i}=\frac{a_{i}}{\sum_{j=1}^{J}a_{j}}\,\forall i$
and the mode of $\theta_{i}$ is $\frac{a_{i}-1}{-1+\sum_{j=1}^{J}a_{j}}$
if $a_{i}>1$
- Iff $a_{j}=1\,\forall j$, $f\left(\left.\boldsymbol{\theta}\right|\boldsymbol{a}=\mathbf{1}\right)$
is constant over $\Theta$ (simplexes)

## Data-Generating Process with Ordinal Predictors

<div class="columns-2">
$$\alpha \thicksim ??? \\
  \forall k: \beta_k \thicksim ??? \\
  \theta_1, \dots , \theta_{J - 1} \thicksim Dirichlet \left(a_1, \dots , a_{J - 1}\right) \\
  \gamma \thicksim ??? \\
  \forall n: \mu_n \equiv \alpha + \sum_{k = 1}^K \beta_k x_{nk} + \gamma \sum_{j = 1}^{c_n - 1} \theta_j \\
  \sigma \thicksim ??? \\
  \forall n: \epsilon_n \thicksim \mathcal{N}\left(0,\sigma\right) \\
  \forall n: y_n \equiv \mu_n + \epsilon_n$$

* Each $c_n$ is a KNOWN category, such as in "Is your family income between \$0 and \$20,000, 
\$20,000 and \$50,000, \$50,000 and \$100,000, \$100,000 and \$200,000, or more than \$200,000?"
* $\gamma$ can be interpreted as the effect of going from the lowest category to the highest
* Since $0 \leq \sum_{j = 1}^{c_n - 1} \theta_j \leq 1$, the sum is the fraction of $\gamma$
  of going from lowest category to $c_n$
</div>

## Ordinal Predictors in Polling

```{r, warning = FALSE, message = FALSE}
poll <- readRDS("GooglePoll.rds") # WantToWin is coded as 1 for Romney and 0 for Obama
library(dplyr)
collapsed <- filter(poll, !is.na(WantToWin)) %>%
             group_by(Region, Gender, Urban_Density, Age, Income) %>%
             summarize(Romney = sum(grepl("Romney", WantToWin)), Obama = n() - Romney) %>%
             na.omit
```
```{r, president, cache = TRUE, results = "hide", warning = FALSE, message = FALSE}
post <- brm(Romney | trials(Romney + Obama) ~ Region + Gender + Urban_Density + 
              # Age and Income are restricted to have monotonic effects
              mo(Age) + mo(Income), data = collapsed, family = binomial(link = "logit"),
            prior = prior("logistic(0,1)", class = "b"))

```
* For more examples, see
  https://cran.r-project.org/package=brms/vignettes/brms_monotonic.html

## Results of Model with Ordinal Predictors {.smaller}

```{r, output.lines = -c(1:8), echo = FALSE}
post
```

## Effect of Age Plot

```{r, message = FALSE}
plot(conditional_effects(post, effects = "Age")) # vertical axis is in log-odds
```

## Effect of Income Plot

```{r, message = FALSE}
plot(conditional_effects(post, effects = "Income")) # forced monotonic but maybe wrong?
```

## Data-Generating Process: Beta-Binomial Models


<div class="columns-2">
* $c_n$ is the category for the $n$-th observation;
  $N_j$ is the number of observations in group $j$
$$\forall k: \gamma_k \thicksim ??? \\
  \forall n: \mu_n = 1 / \left(1 + e^{-\gamma_{c_n}}\right) \\
  \phi \thicksim ??? \\
  \forall n: \alpha_n \equiv \mu_n \phi \\
  \forall n: \beta_n \equiv \left(1 - \mu_n\right) \phi \\
  \forall n: \pi_n \thicksim Beta\left(\alpha_n, \beta_n\right) \\
  \forall n: y_n \thicksim Bernoulli\left(\pi_n\right) \\
  \forall j: z_j \equiv \sum_{c_n \in j} y_n$$

$\Pr\left(z_j \mid \gamma_1, \dots, \gamma_k, \phi\right) = \\
  \int_0^1  f\left(z_j, \pi_j \mid \mu_j, \phi\right) d\pi_j = \\
  \int_0^1 \Pr\left(z_j \mid \pi_j\right) f\left(\pi_j \mid \alpha_j, \beta_j\right) d\pi_j = \\
  {N_j \choose z_j} \frac{1}{B\left(\alpha_j, \beta_j\right)}
  \int_0^1 \pi_j^{\alpha_j^\ast - 1} 
  \left(1 - \pi_j\right)^{\beta_j^\ast - 1} d\pi_j = \\
  {N_j \choose z_j} \frac{B\left(\alpha_j^\ast, \beta_j^\ast\right)}{B\left(\alpha_j, \beta_j\right)}$
  where $\alpha_j^\ast = \alpha_j + z_j$ and $\beta_j^\ast = \beta_j + N_j - z_j$
</div>

## Connection to Hierarchical Models

* A Beta-binomial model is a hierarchical model because the prior for each $\pi_n$
  is conditional on other unknown parameters that have their own marginal priors in
  $\pi_n \thicksim Beta\left(\alpha_n, \beta_n\right)$
* In this particular case, we can integrate each $\pi_j$ out of the posterior distribution
  of $\gamma_1, \dots, \gamma_k, \phi \mid z_1, \dots, z_J, N_1, \dots, N_J$
* If you CAN analytically integrate parameters out of the posterior distribution, you
  usually SHOULD for computational reasons but you do not HAVE to, which is good in
  the many situations where the integrals are not elementary
* Frequentists MUST integrate "non-parameters" like $\pi_j$ out of the likelihood
  function in order to obtain an integrated likelihood function that can be maximized
  by choosing values of the parameters $\gamma_1, \dots, \gamma_k$ and $\phi$
* Scientific literature vastly overrepresents the few cases where integrals are elementary
  so that Frequentist inference can proceed and underrepresents the many cases where
  integrals are not elementary but MCMC works fine

## Linear Algebra

* Linear algebra is necessary to handle hierarchical models, in general
* We are not going to have much time to cover linear algebra next week, since we need
  to go over the homework and hierarchical models (mostly in one or two dimensions)
* If you have never seen linear algebra before, readings are on the syllabus for Week 13 but
  if you would rather watch videos from past years, see 
  [here](https://courseworks2.columbia.edu/files/7384185/download?download_frd=1) and 
  [there](https://courseworks2.columbia.edu/files/7424264/download?download_frd=1)
* Do not worry about the geometric interpretation of vectors; for computation the algebra
  is most important
* Do not worry about computing inverses or determinants of small matrices; they are 
  computed with functions that also work for not-small matrices
* Focus more on the readings / video for Week 14 on hierarchical models

## Multivariate Normal Distributions

* If $\Pr\left(\left.X \leq x \bigcap Y \leq y \bigcap Z \leq z\right|\boldsymbol{\theta}\right) = 
F\left(\left.x,y,z\right|\boldsymbol{\theta}\right)$ is a triviariate CDF, then the
trivariate PDF is
$\frac{\partial^3}{\partial x \partial y \partial z}F\left(\left.x,y,z\right|\boldsymbol{\theta}\right)$,
which generalizes to 4+ variables 
* Univariate normal distribution has PDF 
  $f\left(x \mid \mu, \sigma\right) = \frac{1}{\sigma \sqrt{2 \pi}} 
  e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}$
* Bivariate normal distribution has a PDF that can be written as the product
  of a marginal normal PDF for $X$ and a conditional normal PDF for $Y \mid X$
$f\left(\left.x,y\right|\mu_X,\mu_Y,\sigma_X,\sigma_Y,\rho\right) =
 f\left(x \mid \mu_X, \sigma_X\right) \times f\left(y \mid x, \mu_X, \mu_Y, \sigma_Y, \rho\right)$
* Thus, the PDF of the trivariate normal distribution should be expressable as the
  product of a marginal normal PDF for $X$, a conditional normal PDF for $Y \mid X$, and
  a conditional normal PDF for $Z \mid Y, X$
* This generalizes to a $K$-variate normal distribution, but you need matrix algebra
  to write the PDF concisely in terms of an expectation vector, $\boldsymbol{\mu}$, and
  covariance matrix, $\boldsymbol{\Sigma}$. We can use $K$-variate normal priors and likelihoods.
